{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from load import load_pseudo, load_condons\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.max_colwidth = 10\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.44 s, sys: 116 ms, total: 4.55 s\n",
      "Wall time: 4.57 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>sequence_i</th>\n",
       "      <th>missing_i</th>\n",
       "      <th>missing_%_i</th>\n",
       "      <th>carb</th>\n",
       "      <th>toby</th>\n",
       "      <th>carb_num</th>\n",
       "      <th>toby_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TA151</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>31842</td>\n",
       "      <td>6.588</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>28410</td>\n",
       "      <td>5.878</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>IC1</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>46071</td>\n",
       "      <td>9.532</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>34714</td>\n",
       "      <td>7.182</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A237</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>44514</td>\n",
       "      <td>9.210</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>35933</td>\n",
       "      <td>7.434</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5920</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>49497</td>\n",
       "      <td>10.241</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>36873</td>\n",
       "      <td>7.629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LiA96</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>44067</td>\n",
       "      <td>9.117</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>34454</td>\n",
       "      <td>7.128</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   sequence  missing  missing_% sequence_i  missing_i  missing_%_i  \\\n",
       "0  TA151  ATGAGT...    31842      6.588  ATGAGT...      28410      5.878     \n",
       "1    IC1  ATGAGT...    46071      9.532  ATGAGT...      34714      7.182     \n",
       "2   A237  ATGAGT...    44514      9.210  ATGAGT...      35933      7.434     \n",
       "3   5920  ATGAGT...    49497     10.241  ATGAGT...      36873      7.629     \n",
       "4  LiA96  ATGAGT...    44067      9.117  ATGAGT...      34454      7.128     \n",
       "\n",
       "    carb   toby  carb_num  toby_num  \n",
       "0   True  False      -2.0      16.0  \n",
       "1  False  False       2.0      14.0  \n",
       "2   True  False      -1.0       4.0  \n",
       "3    NaN    NaN       NaN       NaN  \n",
       "4  False  False       0.0      18.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time records = load_pseudo()\n",
    "numerical_response = pd.read_csv('../data/pseudo/Perron_phenotype-GSU-training.csv')\n",
    "records = records.merge(numerical_response[['strain', 'carb.lag.delta', 'toby.lag.delta']],\n",
    "                        left_on='lab-id', right_on='strain', how='left')\n",
    "records.rename(columns={'carb.lag.delta': 'carb_num', 'toby.lag.delta': 'toby_num'}, inplace=True)\n",
    "records.drop(columns=['strain', 'lab-id'], inplace=True)\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (records['toby'].notna() & records['carb'].notna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22 seconds\n",
    "%time o_c = load_condons('../data/pseudo/concatenated.fasta')\n",
    "%time i_c = load_condons('../data/pseudo/concatenated_naive_impute.fasta')\n",
    "\n",
    "# 1.5 minutes\n",
    "d = {}\n",
    "for label, content in o_c.iteritems():\n",
    "    d.update(content.value_counts().to_dict())\n",
    "d_sorted = dict(sorted(d.items(), key=lambda x: x[1], reverse=True))\n",
    "mapping = {key: i for i, key in enumerate(d_sorted.keys())}\n",
    "\n",
    "import json\n",
    "with open('../data/pseudo/preprocess/others/condon_mapping.json', 'w') as output:\n",
    "    json.dump(mapping, output, indent='\\t')\n",
    "\n",
    "import json\n",
    "with open('../data/pseudo/preprocess/others/condon_mapping.json', 'r') as input_:\n",
    "    mapping = json.load(input_)\n",
    "\n",
    "# 22 seconds\n",
    "%time o_c_ = o_c.applymap(lambda x: mapping[x])\n",
    "%time i_c_ = i_c.applymap(lambda x: mapping[x])\n",
    "np.save('../data/pseudo/preprocess/o_c_-_-.npy', o_c_)\n",
    "np.save('../data/pseudo/preprocess/i_c_-_-.npy', i_c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_c_ = np.load('../data/pseudo/preprocess/o_c_-_-.npy')\n",
    "i_c_ = np.load('../data/pseudo/preprocess/i_c_-_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove based on SNP counts\n",
    "similar to variance threshold but seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 minutes\n",
    "%time variant_counts_o = o_c.apply(pd.Series.value_counts, axis=0)\n",
    "%time variant_counts_i = i_c.apply(pd.Series.value_counts, axis=0)\n",
    "np.save('../data/pseudo/preprocess/others/variant_counts_o.npy', variant_counts_o)\n",
    "np.save('../data/pseudo/preprocess/others/variant_counts_i.npy', variant_counts_i)\n",
    "\n",
    "variant_counts_o = pd.DataFrame(np.load('../data/pseudo/preprocess/others/variant_counts_o.npy'))\n",
    "variant_counts_i = pd.DataFrame(np.load('../data/pseudo/preprocess/others/variant_counts_i.npy'))\n",
    "\n",
    "# True     85753\n",
    "variant_max_counts_o = variant_counts_o.max()\n",
    "(pd.Series(variant_max_counts_o<121)).value_counts()\n",
    "\n",
    "# True      56191\n",
    "variant_max_counts_i = variant_counts_i.max()\n",
    "(variant_max_counts_i<121).value_counts()\n",
    "\n",
    "o_c_v = o_c_[mask][:, variant_max_counts_o<121]\n",
    "i_c_v = i_c_[mask][:, variant_max_counts_i<121]\n",
    "np.save('../data/pseudo/preprocess/o_c_v_-.npy', o_c_v)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_-.npy', i_c_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi^2$ on the previous result\n",
    "because some features are all 0's, so gives `divide by 0` warning\n",
    "\n",
    "no warning if we remove those features (on the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "o_c_x = SelectKBest(chi2, k=85753//2).fit_transform(o_c_v, records['toby'][mask].astype('i4'))\n",
    "i_c_x = SelectKBest(chi2, k=56191//2).fit_transform(i_c_v, records['toby'][mask].astype('i4'))\n",
    "\n",
    "np.save('../data/pseudo/preprocess/o_c_x_-.npy', o_c_x)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_-.npy', i_c_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_c_v = np.load('../data/pseudo/preprocess/o_c_v_-.npy')\n",
    "i_c_v = np.load('../data/pseudo/preprocess/i_c_v_-.npy')\n",
    "o_c_x = np.load('../data/pseudo/preprocess/o_c_x_-.npy')\n",
    "i_c_x = np.load('../data/pseudo/preprocess/i_c_x_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strkernel.mismatch_kernel import MismatchKernel\n",
    "\n",
    "%time o_c__s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_)\n",
    "%time i_c__s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_)\n",
    "np.save('../data/pseudo/preprocess/o_c_-_s.npy', o_c__s.kernel)\n",
    "np.save('../data/pseudo/preprocess/i_c_-_s.npy', i_c__s.kernel)\n",
    "\n",
    "%time o_c_v_s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_v)\n",
    "%time i_c_v_s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_v)\n",
    "np.save('../data/pseudo/preprocess/o_c_v_s.npy', o_c_v_s.kernel)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_s.npy', i_c_v_s.kernel)\n",
    "\n",
    "%time o_c_x_s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_x)\n",
    "%time i_c_x_s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_x)\n",
    "np.save('../data/pseudo/preprocess/o_c_x_s.npy', o_c_x_s.kernel)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_s.npy', i_c_x_s.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%time o_c__p = PCA(n_components=119).fit_transform(o_c_)\n",
    "%time i_c__p = PCA(n_components=119).fit_transform(i_c_)\n",
    "np.save('../data/pseudo/preprocess/o_c_-_p.npy', o_c__p)\n",
    "np.save('../data/pseudo/preprocess/i_c_-_p.npy', i_c__p)\n",
    "\n",
    "%time o_c_v_p = PCA(n_components=119).fit_transform(o_c_v)\n",
    "%time i_c_v_p = PCA(n_components=119).fit_transform(i_c_v)\n",
    "np.save('../data/pseudo/preprocess/o_c_v_p.npy', o_c_v_p)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_p.npy', i_c_v_p)\n",
    "\n",
    "%time o_c_x_p = PCA(n_components=119).fit_transform(o_c_x)\n",
    "%time i_c_x_p = PCA(n_components=119).fit_transform(i_c_x)\n",
    "np.save('../data/pseudo/preprocess/o_c_x_p.npy', o_c_x_p)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_p.npy', i_c_x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%time o_c__t = TSNE(n_components=3).fit_transform(o_c_)\n",
    "%time i_c__t = TSNE(n_components=3).fit_transform(i_c_)\n",
    "np.save('../data/pseudo/preprocess/o_c_-_t.npy', o_c__t)\n",
    "np.save('../data/pseudo/preprocess/i_c_-_t.npy', i_c__t)\n",
    "\n",
    "%time o_c_v_t = TSNE(n_components=3).fit_transform(o_c_v)\n",
    "%time i_c_v_t = TSNE(n_components=3).fit_transform(i_c_v)\n",
    "np.save('../data/pseudo/preprocess/o_c_v_t.npy', o_c_v_t)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_t.npy', i_c_v_t)\n",
    "\n",
    "%time o_c_x_t = TSNE(n_components=3).fit_transform(o_c_x)\n",
    "%time i_c_x_t = TSNE(n_components=3).fit_transform(i_c_x)\n",
    "np.save('../data/pseudo/preprocess/o_c_x_t.npy', o_c_x_t)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_t.npy', i_c_x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify all possible combinations are created\n",
    "import os\n",
    "d = os.listdir('../data/pseudo/preprocess/')\n",
    "s = {'{}_{}_{}_{}.npy'.format(impute, c_or_n, selection, extraction) for impute in 'io' for c_or_n in 'nc' for selection in '-vx' for extraction in '-pts'}\n",
    "len(s - set(d)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the numerical data and use onehot encoder\n",
    "s = {'{}_c_{}_{}.npy'.format(impute, selection, extraction)\n",
    "     for impute in 'io'\n",
    "     for selection in '-vx'\n",
    "     for extraction in '-pts'}\n",
    "\n",
    "data = {d: np.load(os.path.join('../data/pseudo/preprocess', d)) for d in s}\n",
    "# mask all data to remove x with NAN labels\n",
    "for k, v in data.items():\n",
    "    if v.shape[0] != 119:\n",
    "        data[k] = v[mask]\n",
    "\n",
    "for file, X in data.items():\n",
    "    encoder = OneHotEncoder(categories='auto', sparse=False, dtype=np.int32)\n",
    "    %time X_encode = encoder.fit_transform(X)\n",
    "    \n",
    "    np.save(os.path.join('../data/pseudo/preprocess/onehot/', file), X_encode)\n",
    "    with open(os.path.join('../data/pseudo/preprocess/onehot-encoder/', file[:file.index('.')]), 'wb') as output:\n",
    "        pickle.dump(encoder, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
