{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from load import load_staph, load_nucleotides\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.max_colwidth = 10\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.93 s, sys: 149 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>sequence_i</th>\n",
       "      <th>missing_i</th>\n",
       "      <th>missing_%_i</th>\n",
       "      <th>resp</th>\n",
       "      <th>Total.Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2511</td>\n",
       "      <td>0.255</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2356</td>\n",
       "      <td>0.240</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NRS002</td>\n",
       "      <td>------...</td>\n",
       "      <td>25278</td>\n",
       "      <td>2.571</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2236</td>\n",
       "      <td>0.227</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NRS003</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>48213</td>\n",
       "      <td>4.904</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2253</td>\n",
       "      <td>0.229</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>ATGAAA...</td>\n",
       "      <td>2442</td>\n",
       "      <td>0.248</td>\n",
       "      <td>ATGAAA...</td>\n",
       "      <td>2088</td>\n",
       "      <td>0.212</td>\n",
       "      <td>False</td>\n",
       "      <td>473.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>3885</td>\n",
       "      <td>0.395</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.219</td>\n",
       "      <td>False</td>\n",
       "      <td>6686.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   sequence  missing  missing_% sequence_i  missing_i  missing_%_i  \\\n",
       "0  NRS001  ATGAAC...     2511      0.255  ATGAAC...       2356      0.240     \n",
       "1  NRS002  ------...    25278      2.571  ATGAAC...       2236      0.227     \n",
       "2  NRS003  ATGAAC...    48213      4.904  ATGAAC...       2253      0.229     \n",
       "3  NRS021  ATGAAA...     2442      0.248  ATGAAA...       2088      0.212     \n",
       "4  NRS022  ATGAAC...     3885      0.395  ATGAAC...       2154      0.219     \n",
       "\n",
       "    resp  Total.Area  \n",
       "0  False      0.000   \n",
       "1  False      0.000   \n",
       "2  False      0.000   \n",
       "3  False    473.152   \n",
       "4  False   6686.806   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time records = load_staph()\n",
    "numerical_response = pd.read_csv('../data/staph/nrs_metadata3.txt', delimiter='\\t')\n",
    "numerical_response\n",
    "records = records.merge(numerical_response[['sample_tag', 'Total.Area']],\n",
    "                        left_on='id', right_on='sample_tag', how='left')\n",
    "records.drop(columns='sample_tag', inplace=True)\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = records['resp'].notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_n = np.load('../data/pseudo/preprocess/o_n_-_-.npy')\n",
    "i_n = np.load('../data/pseudo/preprocess/i_n_-_-.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 1.6 s, total: 1min 32s\n",
      "Wall time: 1min 27s\n",
      "CPU times: user 1min 29s, sys: 1.41 s, total: 1min 30s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "# 1.5 minutes\n",
    "%time o_n = load_nucleotides('../data/staph/core_gene_alignment-narsa.fasta')\n",
    "%time i_n = load_nucleotides('../data/staph/core_gene_alignment-narsa_naive_impute.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 2.06 s, total: 1min 38s\n",
      "Wall time: 1min 31s\n",
      "CPU times: user 1min 36s, sys: 1.75 s, total: 1min 37s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "# 1.5 minutes\n",
    "forward = str.maketrans('-ACTGN', '012345')\n",
    "def transformation(str):\n",
    "    return [int(i) for i in str.translate(forward)]\n",
    "%time o_n = pd.DataFrame(records['sequence'].apply(transformation).to_list())\n",
    "%time i_n = pd.DataFrame(records['sequence_i'].apply(transformation).to_list())\n",
    "np.save('../data/staph/preprocess/o_n_-_-.npy', o_n)\n",
    "np.save('../data/staph/preprocess/i_n_-_-.npy', i_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.01)\n",
    "\n",
    "# justification(not rigorous) for why < 0.016 is the threshold to drop a column\n",
    "a, b = 4, 3\n",
    "arr = np.ones((122, 1))*a\n",
    "arr[:2] = b\n",
    "np.var(arr)\n",
    "\n",
    "o_n_v = selector.fit_transform(o_n)\n",
    "o_n_v_selected = pd.Series(selector.get_support())\n",
    "o_n_v_selected.value_counts()\n",
    "\n",
    "i_n_v = selector.fit_transform(i_n)\n",
    "i_n_v_selected = pd.Series(selector.get_support())\n",
    "i_n_v_selected.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove based on SNP counts\n",
    "similar to variance threshold but seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 minutes each\n",
    "%time snp_counts_o = o_n.apply(pd.Series.value_counts, axis=0)\n",
    "%time snp_counts_i = i_n.apply(pd.Series.value_counts, axis=0)\n",
    "np.save('../data/staph/preprocess/others/snp_counts_o.npy', snp_counts_o.to_numpy())\n",
    "np.save('../data/staph/preprocess/others/snp_counts_i.npy', snp_counts_i.to_numpy())\n",
    "\n",
    "snp_counts_o = pd.DataFrame(np.load('../data/staph/preprocess/others/snp_counts_o.npy'))\n",
    "snp_counts_i = pd.DataFrame(np.load('../data/staph/preprocess/others/snp_counts_i.npy'))\n",
    "\n",
    "# True     218693\n",
    "snp_max_counts_o = snp_counts_o.max()\n",
    "(snp_max_counts_o<124).value_counts()\n",
    "\n",
    "# True     42467\n",
    "snp_max_counts_i = snp_counts_i.max()\n",
    "(snp_max_counts_i<124).value_counts()\n",
    "\n",
    "o_n_v = o_n[mask].loc[:, (snp_max_counts_o<124)]\n",
    "i_n_v = i_n[mask].loc[:, (snp_max_counts_i<124)]\n",
    "np.save('../data/staph/preprocess/o_n_v_-.npy', o_n_v)\n",
    "np.save('../data/staph/preprocess/i_n_v_-.npy', i_n_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi^2$ on the previous result\n",
    "because some features are all 0's, so gives `divide by 0` warning\n",
    "\n",
    "no warning if we remove those features (on the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "o_n_x = SelectKBest(chi2, k=218693//2).fit_transform(o_n_v, records['resp'][mask].astype('i4'))\n",
    "i_n_x = SelectKBest(chi2, k=42467//2).fit_transform(i_n_v, records['resp'][mask].astype('i4'))\n",
    "np.save('../data/staph/preprocess/o_n_x_-.npy', o_n_x)\n",
    "np.save('../data/staph/preprocess/i_n_x_-.npy', i_n_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_n_v = np.load('../data/staph/preprocess/o_n_v_-.npy')\n",
    "i_n_v = np.load('../data/staph/preprocess/i_n_v_-.npy')\n",
    "o_n_x = np.load('../data/staph/preprocess/o_n_x_-.npy')\n",
    "i_n_x = np.load('../data/staph/preprocess/i_n_x_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 58min 49s, sys: 17min 14s, total: 6h 16min 3s\n",
      "Wall time: 14min 17s\n",
      "CPU times: user 5h 51min 48s, sys: 16min 54s, total: 6h 8min 42s\n",
      "Wall time: 14min 16s\n",
      "CPU times: user 8min 37s, sys: 1min 19s, total: 9min 56s\n",
      "Wall time: 2min 45s\n",
      "CPU times: user 28 s, sys: 1.48 s, total: 29.5 s\n",
      "Wall time: 29.5 s\n",
      "CPU times: user 1min 14s, sys: 4.57 s, total: 1min 19s\n",
      "Wall time: 1min 19s\n",
      "CPU times: user 15.4 s, sys: 648 ms, total: 16 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "from strkernel.mismatch_kernel import MismatchKernel\n",
    "\n",
    "# 14 minutes each\n",
    "%time o_n__s = MismatchKernel(l=6, k=3, m=1).get_kernel(o_n)\n",
    "%time i_n__s = MismatchKernel(l=6, k=3, m=1).get_kernel(i_n)\n",
    "np.save('../data/staph/preprocess/o_n_-_s.npy', o_n__s.kernel)\n",
    "np.save('../data/staph/preprocess/i_n_-_s.npy', i_n__s.kernel)\n",
    "\n",
    "# 3 and 1 minutes\n",
    "%time o_n_v_s = MismatchKernel(l=6, k=3, m=1).get_kernel(o_n_v)\n",
    "%time i_n_v_s = MismatchKernel(l=6, k=3, m=1).get_kernel(i_n_v)\n",
    "np.save('../data/staph/preprocess/o_n_v_s.npy', o_n_v_s.kernel)\n",
    "np.save('../data/staph/preprocess/i_n_v_s.npy', i_n_v_s.kernel)\n",
    "\n",
    "# 2 minutes\n",
    "%time o_n_x_s = MismatchKernel(l=6, k=3, m=1).get_kernel(o_n_x)\n",
    "%time i_n_x_s = MismatchKernel(l=6, k=3, m=1).get_kernel(i_n_x)\n",
    "np.save('../data/staph/preprocess/o_n_x_s.npy', o_n_x_s.kernel)\n",
    "np.save('../data/staph/preprocess/i_n_x_s.npy', i_n_x_s.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 18s, sys: 18.4 s, total: 10min 36s\n",
      "Wall time: 19.4 s\n",
      "CPU times: user 10min 22s, sys: 18.8 s, total: 10min 41s\n",
      "Wall time: 19.6 s\n",
      "CPU times: user 2min 5s, sys: 3.89 s, total: 2min 9s\n",
      "Wall time: 3.92 s\n",
      "CPU times: user 20 s, sys: 728 ms, total: 20.7 s\n",
      "Wall time: 577 ms\n",
      "CPU times: user 1min 5s, sys: 2.14 s, total: 1min 7s\n",
      "Wall time: 1.87 s\n",
      "CPU times: user 10.1 s, sys: 391 ms, total: 10.4 s\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%time o_n__p = PCA(n_components=124).fit_transform(o_n)\n",
    "%time i_n__p = PCA(n_components=124).fit_transform(i_n)\n",
    "np.save('../data/staph/preprocess/o_n_-_p.npy', o_n__p)\n",
    "np.save('../data/staph/preprocess/i_n_-_p.npy', i_n__p)\n",
    "\n",
    "%time o_n_v_p = PCA(n_components=124).fit_transform(o_n_v)\n",
    "%time i_n_v_p = PCA(n_components=124).fit_transform(i_n_v)\n",
    "np.save('../data/staph/preprocess/o_n_v_p.npy', o_n_v_p)\n",
    "np.save('../data/staph/preprocess/i_n_v_p.npy', i_n_v_p)\n",
    "\n",
    "%time o_n_x_p = PCA(n_components=124).fit_transform(o_n_x)\n",
    "%time i_n_x_p = PCA(n_components=124).fit_transform(i_n_x)\n",
    "np.save('../data/staph/preprocess/o_n_x_p.npy', o_n_x_p)\n",
    "np.save('../data/staph/preprocess/i_n_x_p.npy', i_n_x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 34s, sys: 12 s, total: 5min 46s\n",
      "Wall time: 13 s\n",
      "CPU times: user 5min 27s, sys: 11.6 s, total: 5min 39s\n",
      "Wall time: 12.8 s\n",
      "CPU times: user 1min 16s, sys: 2.29 s, total: 1min 18s\n",
      "Wall time: 4.47 s\n",
      "CPU times: user 16.6 s, sys: 478 ms, total: 17 s\n",
      "Wall time: 2.56 s\n",
      "CPU times: user 39.9 s, sys: 1.2 s, total: 41.1 s\n",
      "Wall time: 3.42 s\n",
      "CPU times: user 10.6 s, sys: 263 ms, total: 10.8 s\n",
      "Wall time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%time o_n__t = TSNE(n_components=3).fit_transform(o_n)\n",
    "%time i_n__t = TSNE(n_components=3).fit_transform(i_n)\n",
    "np.save('../data/staph/preprocess/o_n_-_t.npy', o_n__t)\n",
    "np.save('../data/staph/preprocess/i_n_-_t.npy', i_n__t)\n",
    "\n",
    "%time o_n_v_t = TSNE(n_components=3).fit_transform(o_n_v)\n",
    "%time i_n_v_t = TSNE(n_components=3).fit_transform(i_n_v)\n",
    "np.save('../data/staph/preprocess/o_n_v_t.npy', o_n_v_t)\n",
    "np.save('../data/staph/preprocess/i_n_v_t.npy', i_n_v_t)\n",
    "\n",
    "%time o_n_x_t = TSNE(n_components=3).fit_transform(o_n_x)\n",
    "%time i_n_x_t = TSNE(n_components=3).fit_transform(i_n_x)\n",
    "np.save('../data/staph/preprocess/o_n_x_t.npy', o_n_x_t)\n",
    "np.save('../data/staph/preprocess/i_n_x_t.npy', i_n_x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "s = {'{}_n_{}_{}.npy'.format(impute, selection, extraction)\n",
    "     for impute in 'io'\n",
    "     for selection in '-vx'\n",
    "     for extraction in '-pts'}\n",
    "\n",
    "data_u = {d: np.load(os.path.join('../data/staph/preprocess', d)) for d in s}\n",
    "# mask all data to remove x with NAN labels\n",
    "for k, v in data_u.items():\n",
    "    if v.shape[0] != 124:\n",
    "        data_u[k] = v[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 ms, sys: 1.21 ms, total: 40.7 ms\n",
      "Wall time: 39.3 ms\n",
      "CPU times: user 38.9 ms, sys: 512 µs, total: 39.4 ms\n",
      "Wall time: 39.5 ms\n",
      "CPU times: user 2.13 ms, sys: 99 µs, total: 2.23 ms\n",
      "Wall time: 2.27 ms\n",
      "CPU times: user 1min 28s, sys: 3.4 s, total: 1min 32s\n",
      "Wall time: 1min 15s\n",
      "CPU times: user 986 µs, sys: 3.18 ms, total: 4.17 ms\n",
      "Wall time: 4.21 ms\n",
      "CPU times: user 737 µs, sys: 266 µs, total: 1 ms\n",
      "Wall time: 1.03 ms\n",
      "CPU times: user 14.9 ms, sys: 958 µs, total: 15.8 ms\n",
      "Wall time: 15.9 ms\n",
      "CPU times: user 18.1 ms, sys: 6.33 ms, total: 24.4 ms\n",
      "Wall time: 24.5 ms\n",
      "CPU times: user 4.81 s, sys: 183 ms, total: 4.99 s\n",
      "Wall time: 1.74 s\n",
      "CPU times: user 2.88 ms, sys: 4.57 ms, total: 7.45 ms\n",
      "Wall time: 7.16 ms\n",
      "CPU times: user 19.2 ms, sys: 113 µs, total: 19.3 ms\n",
      "Wall time: 19.4 ms\n",
      "CPU times: user 16.7 ms, sys: 0 ns, total: 16.7 ms\n",
      "Wall time: 16.8 ms\n",
      "CPU times: user 15.5 ms, sys: 0 ns, total: 15.5 ms\n",
      "Wall time: 15.6 ms\n",
      "CPU times: user 27.9 s, sys: 1.01 s, total: 29 s\n",
      "Wall time: 17.2 s\n",
      "CPU times: user 20.5 ms, sys: 620 µs, total: 21.1 ms\n",
      "Wall time: 21.2 ms\n",
      "CPU times: user 14.6 ms, sys: 0 ns, total: 14.6 ms\n",
      "Wall time: 14.7 ms\n",
      "CPU times: user 14.7 ms, sys: 0 ns, total: 14.7 ms\n",
      "Wall time: 14.8 ms\n",
      "CPU times: user 14.9 ms, sys: 0 ns, total: 14.9 ms\n",
      "Wall time: 15 ms\n",
      "CPU times: user 13.9 ms, sys: 652 µs, total: 14.6 ms\n",
      "Wall time: 14.7 ms\n",
      "CPU times: user 935 µs, sys: 44 µs, total: 979 µs\n",
      "Wall time: 1.01 ms\n",
      "CPU times: user 17.4 s, sys: 567 ms, total: 17.9 s\n",
      "Wall time: 8.54 s\n",
      "CPU times: user 5.96 ms, sys: 541 µs, total: 6.5 ms\n",
      "Wall time: 6.54 ms\n",
      "CPU times: user 6.71 s, sys: 235 ms, total: 6.95 s\n",
      "Wall time: 3.33 s\n",
      "CPU times: user 1min 29s, sys: 3.23 s, total: 1min 32s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "for file, X in data_u.items():\n",
    "    encoder = OneHotEncoder(categories='auto', sparse=False, dtype=np.int32)\n",
    "    %time X_encode = encoder.fit_transform(X)\n",
    "    \n",
    "    np.save(os.path.join('../data/staph/preprocess/onehot', file), X_encode)\n",
    "    with open(os.path.join('../data/staph/preprocess/onehot-encoder', file[:file.index('.')]), 'wb') as output:\n",
    "        pickle.dump(encoder, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e = {d: np.load(os.path.join('../data/staph/preprocess/onehot', d)) for d in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = records['carb'][mask].astype('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['i_n_x_p.npy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y, train_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'class_weight': [None, 'balanced', {0:1, 1:4}, {0:1, 1:8}, {0:1, 1:32}, {0:1, 1:64}, {0:1, 1:128}],\n",
    "              'l1_ratio': [0., 0.2, 0.4, 0.6, 0.8, 1.]}\n",
    "clf = GridSearchCV(LogisticRegression(penalty='elasticnet', solver='saga', max_iter=2000, verbose=1, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 8., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 8., 1., 1., 8., 1., 8., 1., 1., 8., 1., 8., 1.,\n",
       "       1., 1., 1., 8., 1., 1., 8., 8., 1., 1., 1., 1., 8., 1.])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.ones(y_test.shape)\n",
    "weights[y_test] = clf.best_estimator_.class_weight[1]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050847457627118"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(X_test, y_test, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 23],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, clf.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_u_logistic = {}\n",
    "for d, X in data_u.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y, train_size=0.7)\n",
    "    clf = GridSearchCV(LogisticRegression(penalty='elasticnet', solver='saga', max_iter=2000, verbose=False, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_u_logistic[d] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e_logistic = {}\n",
    "for d, X in data_e.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y, train_size=0.7)\n",
    "    clf = GridSearchCV(LogisticRegression(penalty='elasticnet', solver='saga', max_iter=2000, verbose=False, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_e_logistic[d] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [10, 100, 1000],\n",
    "              'min_samples_split': [2, 3],\n",
    "              'min_samples_leaf': [2, 3],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "              'class_weight': [None, 'balanced', {0:1, 1:4}, {0:1, 1:8}, {0:1, 1:32}, {0:1, 1:64}, {0:1, 1:128}]}\n",
    "clf = GridSearchCV(RandomForestClassifier(verbose=0, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 25s, sys: 22.1 s, total: 6min 47s\n",
      "Wall time: 10min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ws/home/zzhang3/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fractio...\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'class_weight': [None, 'balanced', {0: 1, 1: 4},\n",
       "                                          {0: 1, 1: 8}, {0: 1, 1: 32},\n",
       "                                          {0: 1, 1: 64}, {0: 1, 1: 128}],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', None],\n",
       "                         'min_samples_leaf': [2, 3],\n",
       "                         'min_samples_split': [2, 3],\n",
       "                         'n_estimators': [10, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit='balanced_accuracy',\n",
       "             return_train_score=False, scoring=['recall', 'balanced_accuracy'],\n",
       "             verbose=0)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=5,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-1c60142e03f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "weights = np.ones(y_test.shape)\n",
    "weights[y_test] = clf.best_estimator_.class_weight[1]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708333333333334"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(X_test, y_test,\n",
    "#                           sample_weight=weights\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37,  1],\n",
       "       [10,  0]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, clf.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
